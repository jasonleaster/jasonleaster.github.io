
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Machine Learning With Boosting - EOF</title>
  <meta name="author" content="Jason Leaster">

  
  <meta name="description" content="This blog will talk about the theory and implementation about famouse
concept in machine learning – Boosting. All algorithms are implemented in &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://jasonleaster.github.io/blog/2015/12/13/machine-learning-with-boosting/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="EOF" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="/javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">EOF</a></h1>
  
    <h2>Rebuilding The Tower Of Babel</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="sitesearch" value="jasonleaster.github.io">
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/todo">TODO</a></li>
  <li><a href="/recommendation">Recommendation</a></li>
  <li><a href="/about-me">About Me</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">Machine Learning With Boosting</h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2015-12-13T17:00:47+08:00'><span class='date'><span class='date-month'>Dec</span> <span class='date-day'>13</span><span class='date-suffix'>th</span>, <span class='date-year'>2015</span></span> <span class='time'>5:00 pm</span></time>
        
      </p>
    
  </header>


<div class="entry-content"><p>This blog will talk about the theory and implementation about famouse
concept in machine learning – <code>Boosting</code>.</p>

<p>All algorithms are implemented in Python.</p>

<p>There are two main tasks which people want to finish with Machine Learning.</p>

<ul>
  <li>Classification</li>
  <li>Regression</li>
</ul>

<p>There are a lot of other ways to do it but now we focus on <code>boosting</code> algorithm. You know that it’s a fantastic way to make our work done.</p>

<h3 id="adaboost-for-classification">Adaboost for classification</h3>

<p>If you never hear about adaboost, I recommend you to finish the 7-th lab in MIT 6.034. It will help you a lot to understand what I’m taking about. But this lab didn’t build adaboost completely. So, I implement it individually.</p>

<p>Give the input training samples which have tag with it.</p>

<p><img src="/images/img_for_2015_12_13/equation.png" alt="images" /></p>

<p>where x[i] is the feature of the i-th sample point and y[i] is the <code>label</code> (soemtimes we call it as <code>tag</code>) with the sample point.</p>

<p>In this algorithm, there are only two different label of samples {-1, +1}.</p>

<p>Some classifier like decision tree also can work correctly about classification. But it’s also easy to overfitting. So, we can’t use it in some special situation. Instread of using decision tree, we use <code>decision stump</code> which is a special type of decision tree which’s depth is only one. So we call it as <code>decision stump</code>.</p>

<p><code>Yoav Freund</code> and <code>Robert Schapire</code> create this algorithm <strong>AdaBoost</strong> which means adaptive boosting. It combine some weaker classifier into a stronger classifier to avoid overfitting.</p>

<p>Test case:</p>

<p>There are training points with two different label. What if we input a point which’s type is unkown, what the result will be?</p>

<p><img src="/images/img_for_2015_12_13/samples.png" alt="images" /></p>

<p>The test result is below there:</p>

<p><img src="/images/img_for_2015_12_13/result.png" alt="images" /></p>

<p>Just create a object of class <code>Adaboost</code> with your training samples with label. like this:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="kn">import</span> <span class="nn">adaboost</span>
</span><span class="line"><span class="n">a</span> <span class="o">=</span> <span class="n">AdaBoost</span><span class="p">(</span><span class="n">Original_Data</span><span class="p">,</span> <span class="n">Tag</span><span class="p">)</span>
</span><span class="line"><span class="c"># The up bound of training time to avoid the algorithm won&#39;t stop for not meeting the training accuracy.</span>
</span><span class="line"><span class="n">times</span> <span class="o">=</span> <span class="mi">5</span>
</span><span class="line">
</span><span class="line"><span class="n">a</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">times</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="n">a</span><span class="o">.</span><span class="n">prediction</span><span class="p">(</span><span class="n">UnkownPoints</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>API <code>prediction()</code> of class AdaBoost will return the result of prediction according to the model. All job done.</p>

<p>You could find other test case in my repository in github.</p>

<p><a href="https://github.com/jasonleaster/Machine_Learning/tree/master/Adaboost">Implementation of Adaboost in Python</a></p>

<p>You can check the validity of my implementation by the accuracy.</p>

<p><img src="/images/img_for_2015_12_13/samples2.png" alt="images" /></p>

<p>The data used to train the weaker classifier and get that accuracy is showed below there :</p>

<p><img src="/images/img_for_2015_12_13/accuracy.png" alt="images" /></p>

<h3 id="boosting-tree">Boosting Tree</h3>

<p>We have knew to use <code>AdaBoost</code> to do classification. <code>Boosting Tree</code> will help us to do regression.</p>

<p>We also use decision stump as the weak classifier. But implementation of decision stump in this algorithm is not the same as that in AdaBoost.</p>

<p>There are ten samples in my test module:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">Original_Data</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
</span><span class="line">        <span class="p">[</span><span class="mi">2</span><span class="p">],</span>
</span><span class="line">        <span class="p">[</span><span class="mi">3</span><span class="p">],</span>
</span><span class="line">        <span class="p">[</span><span class="mi">4</span><span class="p">],</span>
</span><span class="line">        <span class="p">[</span><span class="mi">5</span><span class="p">],</span>
</span><span class="line">        <span class="p">[</span><span class="mi">6</span><span class="p">],</span>
</span><span class="line">        <span class="p">[</span><span class="mi">7</span><span class="p">],</span>
</span><span class="line">        <span class="p">[</span><span class="mi">8</span><span class="p">],</span>
</span><span class="line">        <span class="p">[</span><span class="mi">9</span><span class="p">],</span>
</span><span class="line">        <span class="p">[</span><span class="mi">10</span><span class="p">],</span>
</span><span class="line">        <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span><span class="line">        <span class="p">])</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>
</span><span class="line">
</span><span class="line"><span class="n">ExpVal</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
</span><span class="line">        <span class="p">[</span><span class="mf">5.70</span><span class="p">],</span>
</span><span class="line">        <span class="p">[</span><span class="mf">5.91</span><span class="p">],</span>
</span><span class="line">        <span class="p">[</span><span class="mf">6.40</span><span class="p">],</span>
</span><span class="line">        <span class="p">[</span><span class="mf">6.80</span><span class="p">],</span>
</span><span class="line">        <span class="p">[</span><span class="mf">7.05</span><span class="p">],</span>
</span><span class="line">        <span class="p">[</span><span class="mf">8.90</span><span class="p">],</span>
</span><span class="line">        <span class="p">[</span><span class="mf">8.70</span><span class="p">],</span>
</span><span class="line">        <span class="p">[</span><span class="mf">9.00</span><span class="p">],</span>
</span><span class="line">        <span class="p">[</span><span class="mf">9.05</span><span class="p">],</span>
</span><span class="line">        <span class="p">[</span><span class="mf">5.56</span><span class="p">]</span>
</span><span class="line">        <span class="p">])</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>The expected value of Original_Data[i] is ExpVal[i]. The input is from 1 to 10. How about to predict the output when the input is 1 or 11?</p>

<p>Let’s test it. Here is the result:
<img src="/images/img_for_2015_12_13/output_of_boosting_tree.png" alt="images" /></p>

<p>Just used 11 weak classifier to construct a stronger classifier to do the regressio. The output is reasonable.</p>

<p>Here is my implementation of <code>Boosting Tree</code>
<a href="https://github.com/jasonleaster/Machine_Learning/tree/master/Boosting_Tree">Implementation of Boosting Tree in Python</a></p>

<p>Reference:</p>

<ol>
  <li>MIT-6.034, Artificial Intelligence. Lab-7</li>
  <li>« The statistic methods » by HangLi.</li>
  <li><a href="https://en.wikipedia.org/wiki/AdaBoost">Wikipedia</a></li>
</ol>

<hr />

<p>Photo by Jason Leaster</p>

<p><img src="/images/img_for_2015_12_13/street.png" alt="images" /></p>
</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">Jason Leaster</span></span>

      




<time class='entry-date' datetime='2015-12-13T17:00:47+08:00'><span class='date'><span class='date-month'>Dec</span> <span class='date-day'>13</span><span class='date-suffix'>th</span>, <span class='date-year'>2015</span></span> <span class='time'>5:00 pm</span></time>
      

<span class="categories">
  
    <a class='category' href='/blog/categories/machinelearning/'>machinelearning</a>
  
</span>


    </p>
    
      <div class="sharing">
  
  
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2015/09/24/binary-search-tree/" title="Previous Post: Binary Search Tree">&laquo; Binary Search Tree</a>
      
      
        <a class="basic-alignment right" href="/blog/2015/12/25/labs-of-mit-6-dot-034/" title="Next Post: Labs of MIT 6.034">Labs of MIT 6.034 &raquo;</a>
      
    </p>
  </footer>
</article>

</div>

<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2016/02/22/exception-control-in-python/">Exception Control in Python</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/02/21/architecture-of-python-virtual-machine/">Architecture of Python Virtual Machine</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/02/19/web-crawler/">Web Crawler</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/02/06/brief-introduction-to-opcodes-in-python/">Brief Introduction to Opcodes in Python</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/02/05/functional-programming-in-python/">Functional Programming in Python</a>
      </li>
    
  </ul>
</section>


<section> 
  <h1>Categories</h1> 
  <ul id="categories"> 
    <li class='category'><a href='/blog/categories/algorithm/'>algorithm (2)</a></li>
<li class='category'><a href='/blog/categories/c/'>c (2)</a></li>
<li class='category'><a href='/blog/categories/cplusplus/'>cplusplus (7)</a></li>
<li class='category'><a href='/blog/categories/essay/'>essay (2)</a></li>
<li class='category'><a href='/blog/categories/labs/'>labs (1)</a></li>
<li class='category'><a href='/blog/categories/machinelearning/'>machinelearning (3)</a></li>
<li class='category'><a href='/blog/categories/python/'>python (7)</a></li>
 
  </ul> 
</section>

  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2016 - Jason Leaster -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  











</body>
</html>
